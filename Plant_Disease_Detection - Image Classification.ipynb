{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Plant Disease Detection",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCCWND7OR4Rz",
        "colab_type": "code",
        "outputId": "7d961acb-c7e2-4c9b-b060-896a93e9c820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGXRZz2omhox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use to reset TF Graphs\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmVfwlPSmmxA",
        "colab_type": "text"
      },
      "source": [
        "Extracting images out of ZIP file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joni08kDTYeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/gdrive/My Drive/test.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n",
        "  \n",
        "with ZipFile('/content/gdrive/My Drive/train.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqXr-PtPTmgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes_train = sorted(list(filter(lambda x: os.path.isdir('/content/train/' + x), os.listdir('/content/train'))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PXFLUjRmyCo",
        "colab_type": "text"
      },
      "source": [
        "Splitting data into Train and Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wz23bE8f2pd",
        "colab_type": "code",
        "outputId": "4272106f-909c-45fd-8325-a687c8812880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!pip install split_folders\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split_folders\n",
            "  Downloading https://files.pythonhosted.org/packages/20/67/29dda743e6d23ac1ea3d16704d8bbb48d65faf3f1b1eaf53153b3da56c56/split_folders-0.3.1-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUUqBt3YgmDw",
        "colab_type": "code",
        "outputId": "27b63d0e-30f6-445b-fa17-154c23ee86ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import split_folders\n",
        "split_folders.ratio('/content/train', output=\"output\", seed=1337, ratio=(.8, .2)) # default values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 44016 files [00:07, 5591.64 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eslG1ifm6pp",
        "colab_type": "text"
      },
      "source": [
        "Generating Image Generators for train and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLmeBf9YUjiA",
        "colab_type": "code",
        "outputId": "77ba7cd2-c5db-4bc5-fba7-ccb63130d0ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size = 128\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/output/train', \n",
        "        target_size=(200, 200),  \n",
        "        batch_size=batch_size,\n",
        "        classes = classes_train,\n",
        "        class_mode='categorical')\n",
        "val_datagen = ImageDataGenerator(rescale=1/255)\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "        '/content/output/val', \n",
        "        target_size=(200, 200),  \n",
        "        batch_size=batch_size,\n",
        "        classes = classes_train,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 35196 images belonging to 39 classes.\n",
            "Found 8820 images belonging to 39 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO3zKkSzmUKe",
        "colab_type": "text"
      },
      "source": [
        "Model Creation \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojVKVJ1DWWCs",
        "colab_type": "code",
        "outputId": "4ce2abf5-2eee-4008-cc10-bfc604d0b037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n",
        "    # The first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),    \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a dense layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 128 neuron in the fully-connected layer\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    # 5 output neurons for 5 classes with the softmax activation\n",
        "    tf.keras.layers.Dense(39, activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 198, 198, 16)      448       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 198, 198, 16)      64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 99, 99, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 97, 97, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 97, 97, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 46, 46, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 21, 21, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 21, 21, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 39)                5031      \n",
            "=================================================================\n",
            "Total params: 234,631\n",
            "Trainable params: 234,151\n",
            "Non-trainable params: 480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJWz1Iaml6V_",
        "colab_type": "text"
      },
      "source": [
        "Compiling Model before training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yEYrrhOXKDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow import keras\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.0005),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxtTnsbCmDWk",
        "colab_type": "text"
      },
      "source": [
        "Creating callbacks and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da3QYzkXlW-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_sample=train_generator.n\n",
        "n_epochs = 30\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint('/content/abc.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "tb = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
        "\n",
        "\n",
        "history = model.fit_generator(\n",
        "        train_generator, \n",
        "        steps_per_epoch=int(total_sample/batch_size),  \n",
        "        epochs=n_epochs,\n",
        "        validation_data = val_generator,\n",
        "        callbacks = [checkpoint, tb],\n",
        "        verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoxzKIXZniZI",
        "colab_type": "text"
      },
      "source": [
        "Saving model other than checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeRUZ4ojnlMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "keras.models.save_model(model, \"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0Yf4B4Nlpm8",
        "colab_type": "text"
      },
      "source": [
        "Loading model back from the file ( saved as checkpoint from callback )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3JFZTTulcc-",
        "colab_type": "code",
        "outputId": "615117d7-3fe7-4502-de46-faef665ab701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = tf.keras.models.load_model(\"/content/gdrive/My Drive/abc.h5\")\n",
        "model.evaluate_generator(val_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18151555059180743, 0.95011336]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2VATKE6j9e5",
        "colab_type": "text"
      },
      "source": [
        "Predicting labels for Testing Data and converting in JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wf-3IDnlBHR",
        "colab_type": "code",
        "outputId": "af2fca3c-6def-46b5-b7ad-030a84aec266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_images = [f for f in os.listdir('/content/test_imgs')]\n",
        "dataset = np.ndarray(shape=(len(test_images), 200, 200, 3))\n",
        "\n",
        "import cv2\n",
        "for i, file_name in enumerate(test_images):\n",
        "  try:\n",
        "    img = cv2.imread('/content/test_imgs/'+file_name)\n",
        "    img_resize = cv2.resize(img, (200,200))\n",
        "    dataset[i] = np.array(img_resize)/255.0\n",
        "  except:\n",
        "    print(file_name)\n",
        "dataset.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11004, 200, 200, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e7RbYvcNgx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.predict_classes(dataset)\n",
        "\n",
        "final_json = {}\n",
        "for file_name, result in zip(test_images, results):\n",
        "  final_json[file_name] = classes_train[result]\n",
        "  \n",
        "  \n",
        "import json\n",
        "with open('prediction.json', 'w') as outfile:\n",
        "    json.dump(final_json, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLxV-L47kFWJ",
        "colab_type": "text"
      },
      "source": [
        "Downloading the JSON File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYK-oqoBkIZH",
        "colab_type": "code",
        "outputId": "f68f7583-c93b-4556-f145-54fde9d8b949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.download('predictions.json')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0dfdaa6945f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predictions.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0mstarted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_threading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: predictions.json"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCkqw1NPjkhh",
        "colab_type": "text"
      },
      "source": [
        "Converting and saving as TFLite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lX_zwCQU6GQ",
        "colab_type": "code",
        "outputId": "073b38f0-d28c-4e38-c09d-79491032ff1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model_file('abc.h5')\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "open(\"abc_opt.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Froze 34 variables.\n",
            "INFO:tensorflow:Converted 34 variables to const ops.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "244376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-RGBb3hnM75",
        "colab_type": "text"
      },
      "source": [
        "Downloading TFLite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YyfpblInPd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('abc_opt.tflite')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX2l9IBxjXHm",
        "colab_type": "text"
      },
      "source": [
        "Loading Tensorflow Lite model back and feeding the validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxz-smrJzF4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"abc_opt.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# input_shape = input_details[0]['shape']\n",
        "# interpreter.set_tensor(input_details[0]['index'], X[0].reshape(1,200,200,3))\n",
        "\n",
        "# interpreter.invoke()\n",
        "\n",
        "# output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "# print(output_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1RFbkEVjcou",
        "colab_type": "text"
      },
      "source": [
        "Comparing the validation set with the TF model and TF_Lite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thwM4Bwkboej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_count, lite_correct_count, incorrect_count, lite_incorrect_count = 0, 0, 0, 0\n",
        "while True:\n",
        "  try:\n",
        "    print(\"New Batch\")\n",
        "    X, y = val_generator.next()\n",
        "    for i in range(len(X)):\n",
        "      interpreter.set_tensor(input_details[0]['index'], X[i].reshape(1,200,200,3))\n",
        "      interpreter.invoke()\n",
        "      output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "      lite_pred_class = np.argmax(output_data)\n",
        "      pred_class = np.argmax(model.predict(X[i].reshape(1,200,200,3)))\n",
        "      orig_class = np.argmax(y[i])\n",
        "      if pred_class == orig_class:\n",
        "        correct_count = correct_count + 1\n",
        "      if lite_pred_class == orig_class:\n",
        "        lite_correct_count = lite_correct_count + 1\n",
        "      if pred_class != orig_class:\n",
        "        incorrect_count = incorrect_count + 1\n",
        "      if lite_pred_class != orig_class:\n",
        "        lite_incorrect_count = lite_incorrect_count + 1\n",
        "    print(\"{} incorrectly identified by tflite\".format(lite_incorrect_count))\n",
        "    print(\"{} incorrectly identified by tf\".format(incorrect_count))\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    break\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}